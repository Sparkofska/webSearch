# Final Project

See code in Folder finalproject

## Notes

 - read project guidelines
 - use Twitter4J for parsing JSON files (if we want)
 - split interest profiles in train and test
 - evaluation using multi-level-relevance
 - diverse digest: remove similar/redundant tweets and present the same amount of information in a more compressed way (nuggets)
 - repeat and improve the first two checkpoints (especially the Anlyzers: combine a few, not only test  3 different)
 - already reports + 2 more parts (Rank fusion and Diversity of information)
      - follow lab guide for rank fusion

# webSearch Lab

## To run
Add the files
 - eval/Answers.csv
 - eval/Questions.csv

## Sources
 - [Learn how to use trec_eval to evaluate your information retrieval system](http://www.rafaelglater.com/en/post/learn-how-to-use-trec_eval-to-evaluate-your-information-retrieval-system)
 - [Lucene Scoring](http://www.lucenetutorial.com/advanced-topics/scoring.html)
 - [Using built-in Analyzers](http://javabeat.net/using-the-built-in-analyzers-in-lucene/)



